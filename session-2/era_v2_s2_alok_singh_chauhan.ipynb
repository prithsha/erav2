{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prithsha/erav2/blob/main/era_v2_s2_alok_singh_chauhan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJptKBxALl-u",
        "outputId": "08c6af74-3d7a-488a-bdf1-e46277376fb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in c:\\users\\1430647\\anaconda3\\envs\\cuda\\lib\\site-packages (1.5.1)Note: you may need to restart the kernel to use updated packages.\n",
            "torch version 2.2.0+cu118\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Importing required libraries \n",
        "# torch is a deep learning framework well integrated with python development\n",
        "import torch\n",
        "\n",
        "#  pre-built classes and functions specifically designed for creating neural networks.\n",
        "# nn.Conv2d form the basic building blocks of neural networks\n",
        "# nn.Module provide a framework for organizing layers and their parameters\n",
        "import torch.nn as nn\n",
        "\n",
        "# torch.nn.functional provides a collection functions for neural networks like:\n",
        "# 1- activation functions like ReLU \n",
        "# 2- Loss functions like L1Loss\n",
        "# 3- Convolution operation like Conv2d\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# optim provides algorithms and tools for optimizing the parameters of your deep learning models.\n",
        "# Example Optimizers: Stochastic Gradient Descent (SGD), Adam, \n",
        "import torch.optim as optim\n",
        "# torchvision library designed for computer vision tasks and also provides data sets\n",
        "from torchvision import datasets, transforms\n",
        "%pip install torchsummary\n",
        "# !pip install torchsummary\n",
        "# tourchsummary library helps in visualizing and analyzing the architecture of deep learning models.\n",
        "from torchsummary import summary\n",
        "\n",
        "print(f\"torch version {torch.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00Owi1LBNY8L",
        "outputId": "2aa1e098-0391-413d-9dd0-e092e281f048"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Checking if support for cuda is available or not so that we can use GPU\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQZaZRGcNLtr",
        "outputId": "6e7a6f4a-2cae-4c86-f0df-58f21653035f"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "# 128 image samples in one batch\n",
        "# Batching: Divides data into smaller batches, reducing memory usage and enabling larger datasets and improved speed.\n",
        "\n",
        "# transforms.Compose process image data prior to feeding it into your models.\n",
        "# operations like Merges multiple transformation operations into a single entity, normalizing or standardizing the pixel values\n",
        "# transforms.Normalize we are passing the mean and standard deviation for a gray scale\n",
        "# Values are 0.1307 indicate that preprocessing is already applied on gray scale otherwise pixel value ranges from 0(Black)-255(White)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Dataloader manages efficient data loading and managing datasets \n",
        "# Now we have got two instances of DataLoader. One for training and other for testing\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3gEjf-xMb-N"
      },
      "source": [
        "# Some Notes on our naive model\n",
        "\n",
        "We are going to write a network based on what we have learnt so far.\n",
        "\n",
        "The size of the input image is 28x28x1. We are going to add as many layers as required to reach RF = 32 \"atleast\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "Sir2LmSVLr_4"
      },
      "outputs": [],
      "source": [
        "# Data r_in, n_in, etc below calculated manually for all layers. \n",
        "# later created a excel to  calculate that. Available at github: https://github.com/prithsha/erav2\n",
        "# File name \"Receptive field out-pixel calculator.xlsx\"\n",
        "\n",
        "class FirstDNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(FirstDNN, self).__init__()\n",
        "    # r_in:1, n_in:28, j_in:1, s:1, r_out:3, n_out:28, j_out:1\n",
        "    self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "    # r_in:3 , n_in:28 , j_in:1 , s:1 , r_out: 5, n_out:28 , j_out:1\n",
        "    self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "    # r_in:5 , n_in:28 , j_in:1 , s:2 , r_out: 6, n_out:14 , j_out:2\n",
        "    self.pool1 = nn.MaxPool2d(2, 2)\n",
        "    # r_in:6, n_in:14 , j_in:2 , s:1 , r_out: 10, n_out:14 , j_out:2\n",
        "    self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "    # r_in:10 , n_in:14 , j_in:2 , s:1 , r_out:14 , n_out:14 , j_out:2\n",
        "    self.conv4 = nn.Conv2d(128, 256, 3, padding = 1)\n",
        "    # r_in: 14, n_in:14 , j_in:2 , s:2 , r_out:16 , n_out:7 , j_out:4\n",
        "    self.pool2 = nn.MaxPool2d(2, 2)\n",
        "    # r_in:16 , n_in:7 , j_in:4 , s:1 , r_out:24 , n_out:5 , j_out:4\n",
        "    self.conv5 = nn.Conv2d(256, 512, 3)\n",
        "    # r_in:24 , n_in:5 , j_in: 4, s:1 , r_out:32 , n_out:3 , j_out:4\n",
        "    self.conv6 = nn.Conv2d(512, 1024, 3)\n",
        "    # r_in:32 , n_in:3 , j_in:4 , s:1 , r_out:40 , n_out:1 , j_out:4\n",
        "    self.conv7 = nn.Conv2d(1024, 10, 3)\n",
        "# Correct values\n",
        "# https://user-images.githubusercontent.com/498461/238034116-7db4cec0-7738-42df-8b67-afa971428d39.png\n",
        "# Function how data is passed from one layer to another\n",
        "  def forward(self, x):\n",
        "    x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x)))))\n",
        "    x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x)))))\n",
        "    x = F.relu(self.conv6(F.relu(self.conv5(x))))\n",
        "    x = self.conv7(x)\n",
        "    # We dont need to calculate relu again as after conv7 we have 10 channels.\n",
        "    # Applying relu on this will reduce negative numbers to 0 which will remove capability of some feature identification \n",
        "    # x = F.relu(x) # this is the last step. Think what ReLU does to our results at this stage!\n",
        "    # print(f\"Before reshape {x.shape}\")\n",
        "    x = x.view(-1, 10)\n",
        "    # print(f\"After reshape {x.shape}\")\n",
        "\n",
        "    # below function performs two operations\n",
        "\n",
        "    # softmax calculates the exponentials of all elements, sums them up and divide each element by SUM. So its normalized probability\n",
        "    # log compress large numbers and spreads smaller ones\n",
        "    return F.log_softmax(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "sxICO4TTNt2H"
      },
      "outputs": [],
      "source": [
        "# creating instance of neural network and sending to hardware\n",
        "model = FirstDNN().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M__MtFIYNwXa",
        "outputId": "6d4ad7af-c132-4d11-c999-1e26658355f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 28, 28]             320\n",
            "            Conv2d-2           [-1, 64, 28, 28]          18,496\n",
            "         MaxPool2d-3           [-1, 64, 14, 14]               0\n",
            "            Conv2d-4          [-1, 128, 14, 14]          73,856\n",
            "            Conv2d-5          [-1, 256, 14, 14]         295,168\n",
            "         MaxPool2d-6            [-1, 256, 7, 7]               0\n",
            "            Conv2d-7            [-1, 512, 5, 5]       1,180,160\n",
            "            Conv2d-8           [-1, 1024, 3, 3]       4,719,616\n",
            "            Conv2d-9             [-1, 10, 1, 1]          92,170\n",
            "================================================================\n",
            "Total params: 6,379,786\n",
            "Trainable params: 6,379,786\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.51\n",
            "Params size (MB): 24.34\n",
            "Estimated Total Size (MB): 25.85\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\1430647\\AppData\\Local\\Temp\\1\\ipykernel_50868\\2523713694.py:41: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        }
      ],
      "source": [
        "# Summarizes each layer (batch dimension, number of output channels, height , width of result feature map )\n",
        "summary(model, input_size=(1, 28, 28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "g_vlC-bdNzo1"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "# start training on training data loader set\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    # We are setting training mode to true\n",
        "    model.train()\n",
        "    # Progress bar\n",
        "    pbar = tqdm(train_loader)\n",
        "    # # Iterate over batches during training\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        # data: A tensor representing the image data for the current batch.\n",
        "        # target: A tensor containing the corresponding labels for the images in the batch.\n",
        "        # Sending to GPU\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        #  Resets the gradients of model parameters to zero before starting backpropagation.\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass through the model to compute predictions for the current batch.\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        #  Performs backpropagation to compute gradients of the loss\n",
        "        loss.backward()\n",
        "        # Updates model parameters based on the calculated gradients.\n",
        "        optimizer.step()\n",
        "        # Updates the progress bar with current loss and batch ID.\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
        "\n",
        "\n",
        "# start test on test data loader set\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0FYVWkGOFBS",
        "outputId": "d4f8c571-7ee1-418d-bc42-5408f01c06b0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/469 [00:00<?, ?it/s]C:\\Users\\1430647\\AppData\\Local\\Temp\\1\\ipykernel_50868\\2523713694.py:41: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n",
            "loss=0.055574432015419006 batch_id=468: 100%|██████████| 469/469 [00:32<00:00, 14.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0552, Accuracy: 9819/10000 (98%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#optimizer function\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# Starting\n",
        "for epoch in range(1, 2):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6agTEkqzz6TZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
